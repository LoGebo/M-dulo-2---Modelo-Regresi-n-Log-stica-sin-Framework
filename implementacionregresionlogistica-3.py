# -*- coding: utf-8 -*-
"""implementacionRegresionLogistica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VSpbLm85QsuAF7KGRLh19qEN6NF1nFET

## Jesús Daniel Martínez García A00833591
"""

# Import drive to connect and interact with Google Drive (so we can import the data)
# Note: This may take a while, but remember to give permission
from google.colab import drive

drive.mount("/content/gdrive")
!pwd # Print working directory

# Commented out IPython magic to ensure Python compatibility.
# Navigate to the path where the dataset is stored and read the csv file
# %cd "/content/gdrive/MyDrive/IA/NOTEBOOKS"
!ls # List files located in defined folder

import pandas as pd

# dataset de kaggle https://www.kaggle.com/datasets/vikramamin/bank-loan-approval-lr-dt-rf-and-auc
df = pd.read_csv('Cancer_Data.csv')
df

#Convertimos  variable categorica para que el modelo pueda manejarla.
df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})

df_x = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean',
           'compactness_mean', 'concavity_mean', 'concave points_mean']]


## Nuestra variable a predecir con la regresión logística será el diagnóstico (0 = Benigno, 1 = Maligno)
df_y = df['diagnosis']

## Aquí utilizaremos la función de train_test_split como la utilizada en la actividad de regresión logistica multiclase para separar nuestro datasets en datos de entrenamiento y prueba
##la función divide los datos en 80% entrenamiento y 20% prueba.

from sklearn.model_selection import train_test_split

#Esto nos servirá para ver si el modelo generaliza bien con otros datos

X_train, X_temp, y_train, y_temp = train_test_split(df_x, df_y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

## Escalar las features nos permitira que el modelo trate a todas las features con igual de importancia

from sklearn.preprocessing import StandardScaler


sc = StandardScaler()

X_train_scaled = sc.fit_transform(X_train)


#transform utilizda en los datos de prueba
X_test_scaled = sc.transform(X_test)

X_val_scaled = sc.transform(X_val)

##inicializacion de theta y columna de 1sss

import numpy as np

# Inicialización del vector theta con valores random (incluyendo el término dell bias)


theta = np.random.randn(len(X_train_scaled[0]) + 1, 1)

# Añadir la columna de unos a X_train_scaled para incluir el bias en X_vect
X_vect = np.c_[np.ones((len(X_train_scaled), 1)), X_train_scaled]
X_test_vect = np.c_[np.ones((len(X_test_scaled), 1)), X_test_scaled]


print(X_vect[:5])
print(X_vect.shape)

##DEFINIMOS LAS FUNCIONES NECESARIAS PARA IMEPLEMENTAR LA REGRESIÓN LOGÍSTICA

import matplotlib.pyplot as plt


##funcion sigmoide convierte en un num entre 0 y 1
def sigmoid_function(X):
    return 1 / (1 + np.exp(-X))

##Regresión logística, utiliza gradient descent para ajustar las thetas, x son los features, y la label,
#alpha el learning reate y los epochs la cantidad de veces que se actulizarán los parametros
def log_regression(X, y, theta, alpha, epochs):
  y_ = np.reshape(y, (len(y), 1)) # shape (150,1)
  N = len(X)
  avg_loss_list = []
  for epoch in range(epochs):
    sigmoid_x_theta = sigmoid_function(X_vect.dot(theta)) # shape: (150,5).(5,1) = (150,1)
    grad = (1/N) * X_vect.T.dot(sigmoid_x_theta - y_) # shapes: (5,150).(150,1) = (5, 1)
    theta = theta - (alpha * grad)
    hyp = sigmoid_function(X_vect.dot(theta)) # shape (150,5).(5,1) = (150,1)
    avg_loss = -np.sum(np.dot(y_.T, np.log(hyp) + np.dot((1-y_).T, np.log(1-hyp)))) / len(hyp)
    if epoch % 1000 == 0:
      print('epoch: {} | avg_loss: {}'.format(epoch, avg_loss))

    avg_loss_list.append(avg_loss)
  plt.plot(np.arange(1, epochs), avg_loss_list[1:], color='red')
  plt.title('Cost function')
  plt.xlabel('Epochs')
  plt.ylabel('Cost')
  plt.show()
  return theta

from sklearn.model_selection import learning_curve
def plot_learning_curve(estimator, X, y, cv, scoring='accuracy'):
    train_sizes, train_scores, val_scores = learning_curve(estimator, X, y, cv=cv, scoring=scoring, n_jobs=-1)

    # Calcular las medias y desviaciones estándar de los scores
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    val_scores_mean = np.mean(val_scores, axis=1)
    val_scores_std = np.std(val_scores, axis=1)

    # Graficar la curva de aprendizaje
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label="Precisión en entrenamiento")
    plt.plot(train_sizes, val_scores_mean, 'o-', color='g', label="Precisión en validación")

    # Rellenar la región de desviación estándar
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color="g")

    # Etiquetas y título
    plt.title("Curva de Aprendizaje para el Modelo de Regresión Logística")
    plt.xlabel("Tamaño del conjunto de entrenamiento")
    plt.ylabel("Precisión")
    plt.legend(loc="best")
    plt.grid()
    plt.show()

#alpha = 0.01
#epochs = 10000

#theta_final = log_regression(X_vect, y_train, theta, alpha, epochs)

#sin utilizar los hiperparametros optimizados
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error

# Define los hiperparámetros sin optimizar
C_value = 0.01
max_iter_value = 500
solver_value = 'lbfgs'
penalty_value = 'l2'

log_reg = LogisticRegression(C=C_value, max_iter=max_iter_value, solver=solver_value, penalty=penalty_value)

# Entrena el modelo
log_reg.fit(X_train_scaled, y_train)

# Hacer predicciones con el conjunto de prueba
y_pred_test = log_reg.predict(X_test_scaled)

# Calcular métricas
accuracy = accuracy_score(y_test, y_pred_test)
print(f'Precisión del modelo: {accuracy * 100:.2f}%')

conf_matrix = confusion_matrix(y_test, y_pred_test)
print("Matriz de Confusión:")
print(conf_matrix)

# Otras métricas
precision = precision_score(y_test, y_pred_test) * 100
recall = recall_score(y_test, y_pred_test) * 100
f1 = f1_score(y_test, y_pred_test) * 100

print(f'Precision: {precision:.2f}%')
print(f'Recall: {recall:.2f}%')
print(f'F1-Score: {f1:.2f}%')

metrics_table = pd.DataFrame({
    'Metric': ['Precision', 'Recall', 'F1-Score'],
    'Score (%)': [precision, recall, f1]
})

print(metrics_table)

# Cross-validation con StratifiedKFold
cv = StratifiedKFold(n_splits=5)

# Graficar la curva de aprendizaje con el modelo actual
plot_learning_curve(log_reg, X_train_scaled, y_train, cv=cv)

##2DO ENTREGABLE USO DE FRAMEWORK PARA ENTRENAR EL MODELO utilizando grid search para optimizar los hiperparametros


param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'max_iter': [100, 500, 1000, 5000],
    'solver': ['liblinear', 'lbfgs'],
    'penalty': ['l2'],
}

# Inicializamos el modelo de regresión logística
log_reg = LogisticRegression()

# Configuramos el Grid Search
grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)

# Entrenamos el modelo con el Grid Search
grid_search.fit(X_train_scaled, y_train)

# Imprimimos los mejores hiperparámetros encontrados
print(f"Mejores hiperparámetros: {grid_search.best_params_}")

# Utilizamos el mejor modelo para hacer predicciones
best_log_reg = grid_search.best_estimator_

# Hacemos predicciones con los datos de prueba
y_pred_test = best_log_reg.predict(X_test_scaled)

# Calculamos la precisión del modelo
accuracy = accuracy_score(y_test, y_pred_test)
print(f'Precisión del modelo con Grid Search: {accuracy * 100:.2f}%')

# Generamos la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_test)
print("Matriz de Confusión:")
print(conf_matrix)

from sklearn.metrics import precision_score, recall_score, f1_score

# Calculamos las otras métricas de rendimiento
precision = precision_score(y_test, y_pred_test) * 100
recall = recall_score(y_test, y_pred_test) * 100
f1 = f1_score(y_test, y_pred_test) * 100
accuracy = accuracy_score(y_test, y_pred_test) * 100

# Imprimimos las métricas
print(f'Precision: {precision:.2f}%')
print(f'Recall: {recall:.2f}%')
print(f'F1-Score: {f1:.2f}%')


# Generamos la tabla de métricas
import pandas as pd

metrics_table = pd.DataFrame({
    'Metric': ['Precision', 'Recall', 'F1-Score'],
    'Score (%)': [precision, recall, f1]
})

# Mostramos la tabla
print(metrics_table)

# PARA MODELO ENTRENADO CON REGRESION LOGISTICA DE SK LEARN
from sklearn.model_selection import StratifiedKFold
# Cross-validation con 5 pliegues
cv = StratifiedKFold(n_splits=5)

# Llamar a la función de la curva de aprendizaje
plot_learning_curve(log_reg, X_train_scaled, y_train, cv=cv)

from sklearn.model_selection import cross_val_score

# Hacemos cross-validation con el mejor modelo encontrado
cv_scores = cross_val_score(best_log_reg, X_train_scaled, y_train, cv=5)

print(f'Cross-Validation Scores: {cv_scores}')
print(f'Promedio de Cross-Validation Score: {cv_scores.mean()}')

# Evaluamos el modelo con el conjunto de validación
y_val_pred = best_log_reg.predict(X_val_scaled)
val_accuracy = accuracy_score(y_val, y_val_pred)
print(f'Precisión del modelo con el conjunto de validación: {val_accuracy * 100:.2f}%')

# Evaluación final en el conjunto de prueba
y_test_pred = best_log_reg.predict(X_test_scaled)
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f'Precisión del modelo con el conjunto de prueba: {test_accuracy * 100:.2f}%')

# Valores de C (controlan la regularización) para probar
C_values = np.logspace(-3, 3, 50)  # Desde 0.001 hasta 1000

train_mse = []
test_mse = []
train_accuracy = []
test_accuracy = []

# Iteramos sobre diferentes valores de C
for C in C_values:
    # Entrenamos el modelo de regresión logística
    log_reg = LogisticRegression(C=C, max_iter=10000)
    log_reg.fit(X_train_scaled, y_train)

    # Predicciones para el conjunto de entrenamiento y prueba
    y_train_pred = log_reg.predict(X_train_scaled)
    y_test_pred = log_reg.predict(X_test_scaled)

    # Calculamos MSE para entrenamiento y prueba
    train_mse.append(mean_squared_error(y_train, y_train_pred))
    test_mse.append(mean_squared_error(y_test, y_test_pred))

    # Calculamos la precisión (accuracy)
    train_accuracy.append(accuracy_score(y_train, y_train_pred))
    test_accuracy.append(accuracy_score(y_test, y_test_pred))

# Graficamos MSE para los conjuntos de entrenamiento y prueba
plt.figure(figsize=(10, 6))
plt.plot(C_values, train_mse, label='Train MSE', color='blue', marker='o')
plt.plot(C_values, test_mse, label='Test MSE', color='orange', marker='o')
plt.xscale('log')  # Escala logarítmica en el eje x (para ver mejor los valores de C)
plt.xlabel('Regularization parameter (C)')
plt.ylabel('Mean Squared Error')
plt.title('MSE vs Regularization (C)')
plt.legend()
plt.grid(True)
plt.show()

# Graficamos la precisión (accuracy) para los conjuntos de entrenamiento y prueba
plt.figure(figsize=(10, 6))
plt.plot(C_values, train_accuracy, label='Train Accuracy', color='blue', marker='o')
plt.plot(C_values, test_accuracy, label='Test Accuracy', color='orange', marker='o')
plt.xscale('log')  # Escala logarítmica en el eje x (para ver mejor los valores de C)
plt.xlabel('Regularization parameter (C)')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Regularization (C)')
plt.legend()
plt.grid(True)
plt.show()

"""##Reporte para primera entrega.

Para el dataset de cáncer data buscamos predecir el label de diagnosis donde m representaba cáncer maligno y b cáncer benigno. Se implementa el modelo de regresión logística al ser un algoritmo efectivo para el problema que representa, viendo que es una clasificación binaria.

Primero se cargan los datos utilizando pandas, se separan las features y labels así como transformar la label categórica a numérica con 0 para benigno y 1 para maligno, lo que facilitaría el uso en el modelo.

Después dividimos los datos de entrenamiento: 80% training y 20% prueba. Esto lo hacemos para evaluar el modelo con datos que no ha visto antes y validar si generaliza o no.

 Se aplicó un standar scaler, que básicamente asegura que todas las features tengan el mismo peso en el entrenamiento y para el de prueba se escalan usando lo mismo que se calculó en los de entrenamiento, uno con fit_transform y el otro solo con transform.

 En las funciones relevantes para la regresión logística se definió la sigmoide y la función para entrenar el modelo utilizando el gradient descent que ajusta las thetas, alpha sería el learning rate, que contra que tran rapido se ajustan las thetas en cada iteración, después los epochs que es la cantidad de veces que se van a actualizar los parametros del modelo.

 Se crea una función predict que utiliza la funcion sigmoide que calcule las probabilidades de que un diagnotico sea maligno (1), si es mayor o igual a 0.5, si es menor, predice benigno (0).

 Se hacen las predicciones sobre los datos de test y se comparan. El accuracy ahí nos da cuántas veces el modelo predijo correctamente, en este caso obtuvo un 96.4%. También, se implementó una matriz de confusión que muestra cómo se comportó el modelo con más detalle: verdaderos negativos (70), es decir, que el modelo predijo bien que 70 personas no tenían cáncer maligno. Falsos positivos (1) el modelo solo predijo mal que una persona tenía cáncer maligno, cuando no. Verdaderos positivos (40), el modelo predijo correctamente que esa cantidad tenía cáncer maligno. Falsos negativos (3), el modelo dio mal que 3 personas no tenían cáncer maligno, cuando sí.

En cuanto a los hiperparámetros, se decidió utilizar la función de grid search, específicamente para ajustar el learning rate y los epochs, durante estas pruebas aunque la función si identificaba una combinación como la mejor (alpha = 0.001 y epochs = 5000) en cuanto a precisión, el rendimiento del modelo cuando use estos parámetros no fue mejor que utilizando otros hiperparámetros que la función no sugería, probablemente debido a un error en la implementación. Decidí utilizar alpha = 0.01 y epochs = 10000 o 5000, viendo ninguna diferencia variando estos epochs y así el modelo se mostraba mejor. Considero que es un área de oportunidad y un aprendizaje importante obtenido al realizar la práctica, pues concluí que la selección de hiperparámetros es un proceso de experiencia, prueba y error.

En conclusión, se pudo aplicar la regresión logística aprendida en clase y empleada en diversas actividades en un dataset nuevo, en este caso para predecir si un cáncer es benigno o maligno, se utilizaron procesos de escalamiento de features y una correcta división de los datos para asegurar un entrenamiento correcto. Se evaluó el modelo y con la matriz de confusión se mostró que predice bien en la mayoría de casos.

---





"""